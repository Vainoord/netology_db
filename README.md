# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её нужно прервать.

Вы как инженер поддержки решили произвести данную операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

### Ответ

1. Найти CRUD операцию через `db.currentOp`. Можно задать БД, в примере ниже это `db1`:

```js
db.currentOp(
  {
    "active" : true,
     "secs_running" : { "$gt" : 180 },
     "ns" : /^db1\./
  }
)
```

Ответом будет:

```js
{
  "inprog": [
       {
        ...
         "effectiveUsers" : [
            {
               "user" : <string>,
               "db" : <string>
            }
         ],
         "opid" : <number>,
         "lsid" : {
            "id" : <UUID>,
            "uid" : <BinData>
         },
         "secs_running" : <NumberLong()>,
         "microsecs_running" : <number>,
         "op" : <string>,
         "ns" : <string>,
         "command" : <document>,
         ...
       },
       ...
   ],
   "fsyncLock": <boolean>,
   "info": <string>,
    "ok": <num>
}
```

Получив искомый `opid`, убедившись, что пользователь действительно запустил эту операцию, можно процесс прервать командой `db.killOp` () с номером `opid`:

```js
db.killOp(opid)
```

2. Проблему долгих запросов можно решать, если конкретный запрос выполнить с методом `.explain()` и изучив работу запроса, можно его оптимизировать.\
Так же можно настроить максимально возможное время выполнения запросов через метод `.maxTimeMS( <milliseconds> )`.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL.
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса.

При масштабировании сервиса до N реплик вы увидели, что:

- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

### Ответ

Механизм Redis предусматривает удаление ключей с истекшим сроком действия 10 раз в секунду (`ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP`) со скоростью до 200 ключей в секунду. Если после очередного цикла удаления количество просроченных ключей будет составлять более 25%, то очистка просроченных ключей будет запускаться непрерывно, пока процент просроченных ключей не станет меньше 25%. В этот момент любые операции записи в Redis блокируются.\
Решением проблемы будет уменьшение количества записей с одинаковым значением TTL, чтобы процент одновременных ключей с истекшим сроком действия не превышал 25%.

## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

### Ответ

Потеря соединения во время выполнения запроса может возникать либо из-за неоптимизированных запросов, либо из-за нехватки времени на выдачу результата по этому запросу. Возможно проблема связана с работой сети.\
Если второй случай не в нашей юрисдикции, то на первую причину можно повлиять следующим образом:

- Оптимизировать клиентские запросы и использовать индексацию запросов.
- На стороне сервера увеличить тайминги у параметров `net_read_timeout` и `net_write_timeout`. Когда сервер читает данные с клиента, `net_read_timeout` является значением тайм-аута, определяющим момент прерывания. Когда сервер пишет клиенту, `net_write_timeout` — это значение тайм-аута, определяющее время прерывания.

## Задача 4

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

### Ответ

`OOM-killer` (Out-Of-Memory Killer) это процесс, который завершает процесс, чтобы спасти ядро ОС от сбоя. Postmaster занял всю свободную память сервера, поэтому был погашен системным вызовом.\
Настройка использования оперативной памяти в файле `postgresql.conf`. Предположим, на сервере 32Gb ОЗУ. В настройках Postgresql нет единого параметра, в котором можно явно указать, сколько памяти использовать, поэтому за использование ОЗУ отвечают следующие параметры:

- `shared_buffers` (integer) - сколько памяти будет выделено для кеширования данных. Рекомендуется установить 15-25% от общего объема ОЗУ.

```
shared_buffers = 4800MB
```

- `work_mem` (integer) - объем памяти, который будет использоваться внутренними операциями сортировки и хэш-таблицами перед записью во временные файлы на диске (Операции сортировки используются для операций упорядочивания, разделения и объединения слиянием. Хэш-таблицы используются в хэш-соединениях и агрегации на основе хэшей).\
Размер `work_mem` можно расчитать по формуле `work_mem = Total RAM * 0.25 / max_connections`, где `max_connections` - одновременное количество подключений к БД, по умолчанию = 100. Можно задать этот параметр для роли - `alter user test set work_mem='80MB';`

```
work_mem = 80MB
```

- `maintenance_work_mem` (integer) - обеспечивает максимальный объем памяти, который будет использоваться операциями обслуживания (vacuum, alter table add foreign key, create index). Можно задать по формуле `Total RAM * 0.05`, рекомендуется выставить значение выше, чем у `work_mem`.

```
maintenance_work_mem = 1600MB
```

- `effective_cache_size` (integer) - сколько памяти доступно для кэширования диска операционной системой и внутри самой базы данных. Это учитывается при оценке стоимости использования индекса; более высокое значение делает более вероятным использование сканирования индекса, более низкое значение повышает вероятность использования последовательного сканирования.\
При установке этого параметра следует учитывать как `shared_buffers`, так и часть дискового кэша ядра, которая будет использоваться для файлов данных PostgreSQL, хотя некоторые данные могут существовать в обоих местах. Кроме того, примите во внимание ожидаемое количество одновременных запросов к разным таблицам, поскольку им придется делить доступное пространство. Не рекомендуют выставлять этот параметр выше 50% от ОЗУ.

```
effective_cache_size = 16000MB
```

Еще нужно обратить внимание на следующее:

- Не держать на одном сервере с СУБД другие несистемные приложения, чтобы уменьшить утилизацию оперативной памяти.
- Физически увеличить размер оперативной памяти на сервере.
- Необходимо установить мониторинг за дисковым пространством сервера и использованием ОЗУ.

---

### Как cдавать задание

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---